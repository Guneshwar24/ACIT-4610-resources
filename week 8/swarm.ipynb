{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAVIGATING TO WAYPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation...\n",
      "Generation 0 - Best Fitness: 6.71\n",
      "Generation 0 - Best Fitness: 6.63\n",
      "Generation 10 - Best Fitness: 3.09\n",
      "Generation 20 - Best Fitness: 0.54\n",
      "Generation 30 - Best Fitness: 0.07\n",
      "Generation 40 - Best Fitness: 0.04\n",
      "\n",
      "Simulation completed!\n",
      "Initial distance to target: 6.71\n",
      "Final distance to target: 0.03\n",
      "Improvement: 99.5%\n",
      "\n",
      "Check 'swarm_evolution.gif' for the animation\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from matplotlib.patches import Circle\n",
    "import os\n",
    "\n",
    "class SwarmRobot:\n",
    "    def __init__(self, x, y, environment_size):\n",
    "        self.position = np.array([x, y])\n",
    "        self.velocity = np.random.randn(2) * 0.1\n",
    "        self.best_position = self.position.copy()\n",
    "        self.environment_size = environment_size\n",
    "        \n",
    "    def update(self, global_best, swarm, generation):\n",
    "        # Parameters that change with generation to show evolution\n",
    "        w = 0.5 * (1 - generation/200)  # Decreasing inertia\n",
    "        c1 = 1.5 * (1 + generation/200)  # Increasing cognitive learning\n",
    "        c2 = 1.5  # Constant social learning\n",
    "        \n",
    "        # Calculate forces\n",
    "        separation = np.zeros(2)\n",
    "        for other in swarm:\n",
    "            if other is not self:\n",
    "                diff = self.position - other.position\n",
    "                dist = max(np.linalg.norm(diff), 0.1)\n",
    "                if dist < 2.0:\n",
    "                    separation += diff / dist\n",
    "        \n",
    "        # Update velocity\n",
    "        r1, r2 = np.random.random(2)\n",
    "        cognitive = c1 * r1 * (self.best_position - self.position)\n",
    "        social = c2 * r2 * (global_best - self.position)\n",
    "        \n",
    "        self.velocity = (w * self.velocity + cognitive + social + 0.1 * separation)\n",
    "        speed = np.linalg.norm(self.velocity)\n",
    "        if speed > 2.0:\n",
    "            self.velocity = (self.velocity / speed) * 2.0\n",
    "            \n",
    "        self.position += self.velocity\n",
    "        self.position = np.clip(self.position, 0, self.environment_size)\n",
    "        \n",
    "        if self.evaluate_fitness() < self.evaluate_fitness(self.best_position):\n",
    "            self.best_position = self.position.copy()\n",
    "    \n",
    "    def evaluate_fitness(self, pos=None):\n",
    "        if pos is None:\n",
    "            pos = self.position\n",
    "        target = np.array([self.environment_size * 0.8, self.environment_size * 0.8])\n",
    "        return np.linalg.norm(pos - target)\n",
    "\n",
    "class SwarmSimulation:\n",
    "    def __init__(self, num_robots=15, environment_size=100):\n",
    "        self.num_robots = num_robots\n",
    "        self.environment_size = environment_size\n",
    "        self.swarm = []\n",
    "        self.global_best = None\n",
    "        self.global_best_value = float('inf')\n",
    "        self.fitness_history = []\n",
    "        self.generation = 0\n",
    "        \n",
    "        # Initialize swarm\n",
    "        for _ in range(num_robots):\n",
    "            x = np.random.uniform(0, environment_size)\n",
    "            y = np.random.uniform(0, environment_size)\n",
    "            self.swarm.append(SwarmRobot(x, y, environment_size))\n",
    "        \n",
    "        # Setup figure\n",
    "        self.fig, (self.ax1, self.ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        self.target = np.array([environment_size * 0.8, environment_size * 0.8])\n",
    "        \n",
    "    def update(self, frame):\n",
    "        self.generation = frame\n",
    "        \n",
    "        # Update global best\n",
    "        for robot in self.swarm:\n",
    "            fitness = robot.evaluate_fitness()\n",
    "            if fitness < self.global_best_value:\n",
    "                self.global_best_value = fitness\n",
    "                self.global_best = robot.position.copy()\n",
    "        \n",
    "        # Update robots\n",
    "        for robot in self.swarm:\n",
    "            robot.update(self.global_best, self.swarm, frame)\n",
    "        \n",
    "        self.fitness_history.append(self.global_best_value)\n",
    "        \n",
    "        # Clear and update plots\n",
    "        self.ax1.clear()\n",
    "        self.ax2.clear()\n",
    "        \n",
    "        # Plot swarm\n",
    "        positions = np.array([robot.position for robot in self.swarm])\n",
    "        self.ax1.scatter(positions[:, 0], positions[:, 1], c='blue', label='Robots')\n",
    "        self.ax1.scatter(self.target[0], self.target[1], c='red', s=100, label='Target')\n",
    "        self.ax1.set_xlim(0, self.environment_size)\n",
    "        self.ax1.set_ylim(0, self.environment_size)\n",
    "        self.ax1.set_title(f'Generation {frame}')\n",
    "        self.ax1.legend()\n",
    "        self.ax1.grid(True)\n",
    "        \n",
    "        # Plot fitness history\n",
    "        self.ax2.plot(self.fitness_history, 'b-', label='Best Fitness')\n",
    "        self.ax2.set_title('Best Fitness Over Time')\n",
    "        self.ax2.set_xlabel('Generation')\n",
    "        self.ax2.set_ylabel('Distance to Target')\n",
    "        self.ax2.grid(True)\n",
    "        self.ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Print progress\n",
    "        if frame % 10 == 0:\n",
    "            print(f\"Generation {frame} - Best Fitness: {self.global_best_value:.2f}\")\n",
    "\n",
    "def create_swarm_evolution_gif(num_generations=50, num_robots=15, environment_size=100):\n",
    "    print(\"Starting simulation...\")\n",
    "    \n",
    "    # Create simulation\n",
    "    sim = SwarmSimulation(num_robots, environment_size)\n",
    "    \n",
    "    # Create animation\n",
    "    anim = FuncAnimation(sim.fig, sim.update, frames=num_generations, \n",
    "                        interval=100, blit=False)\n",
    "    \n",
    "    # Save as GIF\n",
    "    writer = PillowWriter(fps=10)\n",
    "    anim.save('swarm_evolution.gif', writer=writer)\n",
    "    \n",
    "    print(\"\\nSimulation completed!\")\n",
    "    print(f\"Initial distance to target: {sim.fitness_history[0]:.2f}\")\n",
    "    print(f\"Final distance to target: {sim.fitness_history[-1]:.2f}\")\n",
    "    print(f\"Improvement: {((sim.fitness_history[0] - sim.fitness_history[-1])/sim.fitness_history[0]*100):.1f}%\")\n",
    "    print(\"\\nCheck 'swarm_evolution.gif' for the animation\")\n",
    "\n",
    "# Run the simulation and create GIF\n",
    "create_swarm_evolution_gif(num_generations=50, num_robots=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORAGING TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting foraging simulation...\n",
      "Generation 0 - Avg Fitness: 0.00\n",
      "Generation 0 - Avg Fitness: 1.33\n",
      "Generation 10 - Avg Fitness: 4.00\n",
      "Generation 20 - Avg Fitness: 7.33\n",
      "Generation 30 - Avg Fitness: 8.67\n",
      "Generation 40 - Avg Fitness: 9.33\n",
      "Generation 50 - Avg Fitness: 9.33\n",
      "Generation 60 - Avg Fitness: 10.67\n",
      "Generation 70 - Avg Fitness: 10.67\n",
      "Generation 80 - Avg Fitness: 10.67\n",
      "Generation 90 - Avg Fitness: 11.33\n",
      "\n",
      "Simulation completed!\n",
      "Final average fitness: 13.33\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "import random\n",
    "\n",
    "class ForagingRobot:\n",
    "    def __init__(self, x, y, environment_size):\n",
    "        self.position = np.array([x, y])\n",
    "        self.velocity = np.random.randn(2) * 0.1\n",
    "        self.environment_size = environment_size\n",
    "        self.carrying_resource = False\n",
    "        self.energy = 100\n",
    "        self.fitness = 0\n",
    "        self.state = 'searching'  # states: searching, returning, avoiding\n",
    "        self.memory = []  # Remember successful resource locations\n",
    "        \n",
    "    def sense_environment(self, resources, obstacles, base, other_robots):\n",
    "        # Find nearest resource\n",
    "        nearest_resource = None\n",
    "        min_dist = float('inf')\n",
    "        for resource in resources:\n",
    "            if not resource['collected']:\n",
    "                dist = np.linalg.norm(self.position - resource['position'])\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    nearest_resource = resource\n",
    "        \n",
    "        # Check for obstacles\n",
    "        for obstacle in obstacles:\n",
    "            dist = np.linalg.norm(self.position - obstacle)\n",
    "            if dist < 3.0:  # Obstacle detection range\n",
    "                self.state = 'avoiding'\n",
    "                return {'type': 'obstacle', 'position': obstacle}\n",
    "        \n",
    "        # If carrying resource, focus on base\n",
    "        if self.carrying_resource:\n",
    "            self.state = 'returning'\n",
    "            return {'type': 'base', 'position': base}\n",
    "        \n",
    "        # If near resource, collect it\n",
    "        if nearest_resource and min_dist < 2.0:\n",
    "            self.carrying_resource = True\n",
    "            nearest_resource['collected'] = True\n",
    "            self.fitness += 10\n",
    "            self.memory.append(nearest_resource['position'])\n",
    "            self.state = 'returning'\n",
    "            return {'type': 'base', 'position': base}\n",
    "        \n",
    "        return {'type': 'resource', 'position': nearest_resource['position'] if nearest_resource else None}\n",
    "    \n",
    "    def update(self, resources, obstacles, base, other_robots):\n",
    "        # Reduce energy\n",
    "        self.energy -= 0.1\n",
    "        if self.energy <= 0:\n",
    "            return False  # Robot has died\n",
    "        \n",
    "        # Sense environment\n",
    "        target = self.sense_environment(resources, obstacles, base, other_robots)\n",
    "        \n",
    "        # Calculate movement\n",
    "        if target['type'] == 'obstacle':\n",
    "            # Avoid obstacle\n",
    "            diff = self.position - target['position']\n",
    "            self.velocity = diff / np.linalg.norm(diff) * 2.0\n",
    "        \n",
    "        elif target['type'] == 'base' and self.carrying_resource:\n",
    "            # Return to base\n",
    "            diff = base - self.position\n",
    "            dist_to_base = np.linalg.norm(diff)\n",
    "            if dist_to_base < 2.0:\n",
    "                self.carrying_resource = False\n",
    "                self.energy = min(100, self.energy + 30)  # Recharge at base\n",
    "                self.state = 'searching'\n",
    "            else:\n",
    "                self.velocity = diff / dist_to_base * 1.5\n",
    "        \n",
    "        elif target['type'] == 'resource' and target['position'] is not None:\n",
    "            # Move toward resource\n",
    "            diff = target['position'] - self.position\n",
    "            self.velocity = diff / np.linalg.norm(diff)\n",
    "        \n",
    "        else:\n",
    "            # Random search with influence from memory\n",
    "            if len(self.memory) > 0:\n",
    "                # Sometimes check previous successful locations\n",
    "                if random.random() < 0.3:\n",
    "                    memory_point = random.choice(self.memory)\n",
    "                    diff = memory_point - self.position\n",
    "                    self.velocity = diff / np.linalg.norm(diff) * 0.5\n",
    "                else:\n",
    "                    self.velocity += np.random.randn(2) * 0.1\n",
    "            else:\n",
    "                self.velocity += np.random.randn(2) * 0.1\n",
    "        \n",
    "        # Update position\n",
    "        self.velocity = self.velocity / np.linalg.norm(self.velocity)\n",
    "        self.position += self.velocity\n",
    "        \n",
    "        # Boundary conditions\n",
    "        self.position = np.clip(self.position, 0, self.environment_size)\n",
    "        \n",
    "        return True  # Robot is still alive\n",
    "\n",
    "class SwarmSimulation:\n",
    "    def __init__(self, num_robots=10, environment_size=100, num_resources=20, num_obstacles=10):\n",
    "        self.environment_size = environment_size\n",
    "        self.base = np.array([environment_size/2, environment_size/2])\n",
    "        self.resources = []\n",
    "        self.obstacles = []\n",
    "        self.swarm = []\n",
    "        self.generation = 0\n",
    "        self.fitness_history = []\n",
    "        \n",
    "        # Initialize resources\n",
    "        for _ in range(num_resources):\n",
    "            self.resources.append({\n",
    "                'position': np.random.uniform(0, environment_size, 2),\n",
    "                'collected': False\n",
    "            })\n",
    "        \n",
    "        # Initialize obstacles\n",
    "        for _ in range(num_obstacles):\n",
    "            self.obstacles.append(np.random.uniform(0, environment_size, 2))\n",
    "        \n",
    "        # Initialize robots\n",
    "        for _ in range(num_robots):\n",
    "            x = np.random.uniform(0, environment_size)\n",
    "            y = np.random.uniform(0, environment_size)\n",
    "            self.swarm.append(ForagingRobot(x, y, environment_size))\n",
    "        \n",
    "        # Setup visualization\n",
    "        self.fig, (self.ax1, self.ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "    def update(self, frame):\n",
    "        self.generation = frame\n",
    "        \n",
    "        # Update each robot\n",
    "        total_fitness = 0\n",
    "        for robot in self.swarm:\n",
    "            still_alive = robot.update(self.resources, self.obstacles, self.base, self.swarm)\n",
    "            if still_alive:\n",
    "                total_fitness += robot.fitness\n",
    "        \n",
    "        avg_fitness = total_fitness / len(self.swarm)\n",
    "        self.fitness_history.append(avg_fitness)\n",
    "        \n",
    "        # Clear and update plots\n",
    "        self.ax1.clear()\n",
    "        self.ax2.clear()\n",
    "        \n",
    "        # Plot environment\n",
    "        # Base\n",
    "        self.ax1.scatter(self.base[0], self.base[1], c='green', s=200, marker='*', label='Base')\n",
    "        \n",
    "        # Resources\n",
    "        resource_positions = np.array([r['position'] for r in self.resources if not r['collected']])\n",
    "        if len(resource_positions) > 0:\n",
    "            self.ax1.scatter(resource_positions[:, 0], resource_positions[:, 1], \n",
    "                           c='gold', s=50, marker='o', label='Resources')\n",
    "        \n",
    "        # Obstacles\n",
    "        obstacles = np.array(self.obstacles)\n",
    "        self.ax1.scatter(obstacles[:, 0], obstacles[:, 1], \n",
    "                        c='red', s=100, marker='s', label='Obstacles')\n",
    "        \n",
    "        # Robots\n",
    "        robot_positions = np.array([robot.position for robot in self.swarm])\n",
    "        robot_colors = ['blue' if not robot.carrying_resource else 'purple' for robot in self.swarm]\n",
    "        self.ax1.scatter(robot_positions[:, 0], robot_positions[:, 1], \n",
    "                        c=robot_colors, s=80, label='Robots')\n",
    "        \n",
    "        self.ax1.set_xlim(0, self.environment_size)\n",
    "        self.ax1.set_ylim(0, self.environment_size)\n",
    "        self.ax1.set_title(f'Generation {frame}')\n",
    "        self.ax1.legend()\n",
    "        self.ax1.grid(True)\n",
    "        \n",
    "        # Plot fitness history\n",
    "        self.ax2.plot(self.fitness_history, 'b-', label='Average Fitness')\n",
    "        self.ax2.set_title('Swarm Performance Over Time')\n",
    "        self.ax2.set_xlabel('Generation')\n",
    "        self.ax2.set_ylabel('Average Fitness')\n",
    "        self.ax2.grid(True)\n",
    "        self.ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if frame % 10 == 0:\n",
    "            print(f\"Generation {frame} - Avg Fitness: {avg_fitness:.2f}\")\n",
    "\n",
    "def create_foraging_simulation_gif(num_generations=100):\n",
    "    print(\"Starting foraging simulation...\")\n",
    "    \n",
    "    sim = SwarmSimulation(num_robots=15, environment_size=100, \n",
    "                         num_resources=20, num_obstacles=10)\n",
    "    \n",
    "    anim = FuncAnimation(sim.fig, sim.update, frames=num_generations, \n",
    "                        interval=100, blit=False)\n",
    "    \n",
    "    writer = PillowWriter(fps=10)\n",
    "    anim.save('foraging_swarm.gif', writer=writer)\n",
    "    \n",
    "    print(\"\\nSimulation completed!\")\n",
    "    print(f\"Final average fitness: {sim.fitness_history[-1]:.2f}\")\n",
    "\n",
    "# Run the simulation\n",
    "create_foraging_simulation_gif(num_generations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary Robotics - Find target with obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evolutionary Robotics Simulation...\n",
      "Generation 1: Best Fitness = 0.00\n",
      "Generation 2: Best Fitness = 0.00\n",
      "Generation 3: Best Fitness = 0.00\n",
      "Generation 4: Best Fitness = 0.00\n",
      "\n",
      "Simulation completed!\n",
      "Check 'evolutionary_robotics.gif' for the animation\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import random\n",
    "\n",
    "class NeuralController:\n",
    "    def __init__(self, num_inputs=5, num_hidden=4, num_outputs=2):\n",
    "        # Simple neural network for robot control\n",
    "        self.weights1 = np.random.randn(num_inputs, num_hidden)\n",
    "        self.weights2 = np.random.randn(num_hidden, num_outputs)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Neural network forward pass\n",
    "        hidden = np.tanh(np.dot(inputs, self.weights1))\n",
    "        outputs = np.tanh(np.dot(hidden, self.weights2))\n",
    "        return outputs\n",
    "    \n",
    "    def mutate(self, mutation_rate=0.1):\n",
    "        # Mutate weights\n",
    "        self.weights1 += np.random.randn(*self.weights1.shape) * mutation_rate\n",
    "        self.weights2 += np.random.randn(*self.weights2.shape) * mutation_rate\n",
    "\n",
    "class EvolutionaryRobot:\n",
    "    def __init__(self, x, y, environment_size):\n",
    "        self.position = np.array([x, y])\n",
    "        self.angle = np.random.random() * 2 * np.pi\n",
    "        self.environment_size = environment_size\n",
    "        self.controller = NeuralController()\n",
    "        self.fitness = 0\n",
    "        self.sensor_readings = np.zeros(5)  # 5 sensors\n",
    "        self.trail = [self.position.copy()]  # Store position history\n",
    "        \n",
    "    def get_sensor_readings(self, obstacles):\n",
    "        # Simulated distance sensors at different angles\n",
    "        angles = [-np.pi/2, -np.pi/4, 0, np.pi/4, np.pi/2]  # Sensor angles\n",
    "        sensor_range = 20.0\n",
    "        \n",
    "        for i, angle in enumerate(angles):\n",
    "            # Calculate sensor direction\n",
    "            sensor_angle = self.angle + angle\n",
    "            sensor_dir = np.array([np.cos(sensor_angle), np.sin(sensor_angle)])\n",
    "            \n",
    "            # Check distance to obstacles\n",
    "            min_distance = sensor_range\n",
    "            for obstacle in obstacles:\n",
    "                to_obstacle = obstacle - self.position\n",
    "                projection = np.dot(to_obstacle, sensor_dir)\n",
    "                \n",
    "                if 0 <= projection <= sensor_range:\n",
    "                    distance = np.linalg.norm(to_obstacle - projection * sensor_dir)\n",
    "                    if distance < 2.0:  # Sensor beam width\n",
    "                        min_distance = min(min_distance, projection)\n",
    "            \n",
    "            self.sensor_readings[i] = 1.0 - min_distance/sensor_range\n",
    "    \n",
    "    def update(self, obstacles, target):\n",
    "        # Get sensor readings\n",
    "        self.get_sensor_readings(obstacles)\n",
    "        \n",
    "        # Neural network control\n",
    "        outputs = self.controller.forward(self.sensor_readings)\n",
    "        \n",
    "        # Convert outputs to movement\n",
    "        speed = (outputs[0] + 1) * 2  # Scale to 0-4\n",
    "        turn_rate = outputs[1] * np.pi/4  # Scale to ±π/4\n",
    "        \n",
    "        # Update position and angle\n",
    "        self.angle += turn_rate\n",
    "        movement = np.array([np.cos(self.angle), np.sin(self.angle)]) * speed\n",
    "        new_position = self.position + movement\n",
    "        \n",
    "        # Check collision with obstacles\n",
    "        collision = False\n",
    "        for obstacle in obstacles:\n",
    "            if np.linalg.norm(new_position - obstacle) < 2.0:\n",
    "                collision = True\n",
    "                break\n",
    "        \n",
    "        if not collision:\n",
    "            self.position = np.clip(new_position, 0, self.environment_size)\n",
    "            \n",
    "        # Update trail\n",
    "        self.trail.append(self.position.copy())\n",
    "        \n",
    "        # Update fitness based on:\n",
    "        # 1. Distance to target\n",
    "        # 2. Collision penalty\n",
    "        # 3. Movement efficiency\n",
    "        distance_to_target = np.linalg.norm(self.position - target)\n",
    "        self.fitness = 1000 - distance_to_target\n",
    "        if collision:\n",
    "            self.fitness -= 100\n",
    "        \n",
    "        return not collision\n",
    "\n",
    "class EvolutionarySimulation:\n",
    "    def __init__(self, population_size=20, environment_size=100):\n",
    "        self.environment_size = environment_size\n",
    "        self.population_size = population_size\n",
    "        self.generation = 0\n",
    "        self.population = []\n",
    "        self.obstacles = []\n",
    "        self.target = np.array([environment_size * 0.8, environment_size * 0.8])\n",
    "        self.best_fitness_history = []\n",
    "        self.avg_fitness_history = []\n",
    "        \n",
    "        # Initialize obstacles and population\n",
    "        self.initialize_environment()\n",
    "        self.initialize_population()\n",
    "        \n",
    "        # Setup visualization\n",
    "        self.fig = plt.figure(figsize=(15, 5))\n",
    "        self.gs = self.fig.add_gridspec(1, 3)\n",
    "        self.ax_main = self.fig.add_subplot(self.gs[0])\n",
    "        self.ax_fitness = self.fig.add_subplot(self.gs[1])\n",
    "        self.ax_info = self.fig.add_subplot(self.gs[2])\n",
    "        \n",
    "    def initialize_environment(self):\n",
    "        # Create obstacles\n",
    "        for _ in range(10):\n",
    "            self.obstacles.append(\n",
    "                np.random.uniform(0.2, 0.8, 2) * self.environment_size\n",
    "            )\n",
    "            \n",
    "    def initialize_population(self):\n",
    "        for _ in range(self.population_size):\n",
    "            x = np.random.uniform(0, self.environment_size * 0.2)\n",
    "            y = np.random.uniform(0, self.environment_size * 0.2)\n",
    "            self.population.append(EvolutionaryRobot(x, y, self.environment_size))\n",
    "    \n",
    "    def selection_and_reproduction(self):\n",
    "        # Sort population by fitness\n",
    "        self.population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "        \n",
    "        # Keep top half and create offspring\n",
    "        survivors = self.population[:self.population_size//2]\n",
    "        new_population = []\n",
    "        \n",
    "        for robot in survivors:\n",
    "            # Keep survivor\n",
    "            new_robot = EvolutionaryRobot(\n",
    "                np.random.uniform(0, self.environment_size * 0.2),\n",
    "                np.random.uniform(0, self.environment_size * 0.2),\n",
    "                self.environment_size\n",
    "            )\n",
    "            new_robot.controller.weights1 = robot.controller.weights1.copy()\n",
    "            new_robot.controller.weights2 = robot.controller.weights2.copy()\n",
    "            new_population.append(new_robot)\n",
    "            \n",
    "            # Create mutated offspring\n",
    "            offspring = EvolutionaryRobot(\n",
    "                np.random.uniform(0, self.environment_size * 0.2),\n",
    "                np.random.uniform(0, self.environment_size * 0.2),\n",
    "                self.environment_size\n",
    "            )\n",
    "            offspring.controller.weights1 = robot.controller.weights1.copy()\n",
    "            offspring.controller.weights2 = robot.controller.weights2.copy()\n",
    "            offspring.controller.mutate()\n",
    "            new_population.append(offspring)\n",
    "            \n",
    "        self.population = new_population\n",
    "    \n",
    "    def update(self, frame):\n",
    "        if frame > 0 and frame % 100 == 0:  # New generation every 100 frames\n",
    "            self.generation += 1\n",
    "            self.selection_and_reproduction()\n",
    "            \n",
    "            # Record fitness history\n",
    "            fitnesses = [robot.fitness for robot in self.population]\n",
    "            self.best_fitness_history.append(max(fitnesses))\n",
    "            self.avg_fitness_history.append(np.mean(fitnesses))\n",
    "            \n",
    "            print(f\"Generation {self.generation}: Best Fitness = {max(fitnesses):.2f}\")\n",
    "        \n",
    "        # Update robots\n",
    "        for robot in self.population:\n",
    "            robot.update(self.obstacles, self.target)\n",
    "        \n",
    "        # Update visualization\n",
    "        self.ax_main.clear()\n",
    "        self.ax_fitness.clear()\n",
    "        self.ax_info.clear()\n",
    "        \n",
    "        # Plot environment\n",
    "        self.plot_environment()\n",
    "        self.plot_fitness_history()\n",
    "        self.display_info()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def plot_environment(self):\n",
    "        # Plot obstacles\n",
    "        obstacles = np.array(self.obstacles)\n",
    "        self.ax_main.scatter(obstacles[:, 0], obstacles[:, 1], \n",
    "                           c='red', s=100, marker='s', label='Obstacles')\n",
    "        \n",
    "        # Plot target\n",
    "        self.ax_main.scatter(self.target[0], self.target[1], \n",
    "                           c='green', s=200, marker='*', label='Target')\n",
    "        \n",
    "        # Plot robots and their trails\n",
    "        for robot in self.population:\n",
    "            trail = np.array(robot.trail)\n",
    "            self.ax_main.plot(trail[:, 0], trail[:, 1], 'b-', alpha=0.1)\n",
    "            self.ax_main.scatter(robot.position[0], robot.position[1], \n",
    "                               c='blue', s=50)\n",
    "        \n",
    "        self.ax_main.set_xlim(0, self.environment_size)\n",
    "        self.ax_main.set_ylim(0, self.environment_size)\n",
    "        self.ax_main.set_title(f'Generation {self.generation}')\n",
    "        self.ax_main.legend()\n",
    "        self.ax_main.grid(True)\n",
    "    \n",
    "    def plot_fitness_history(self):\n",
    "        if self.best_fitness_history:\n",
    "            self.ax_fitness.plot(self.best_fitness_history, 'r-', \n",
    "                               label='Best Fitness')\n",
    "            self.ax_fitness.plot(self.avg_fitness_history, 'b-', \n",
    "                               label='Average Fitness')\n",
    "            self.ax_fitness.set_title('Fitness Over Generations')\n",
    "            self.ax_fitness.set_xlabel('Generation')\n",
    "            self.ax_fitness.set_ylabel('Fitness')\n",
    "            self.ax_fitness.grid(True)\n",
    "            self.ax_fitness.legend()\n",
    "    \n",
    "    def display_info(self):\n",
    "        self.ax_info.axis('off')\n",
    "        info = [\n",
    "            \"Evolutionary Robotics Demo\",\n",
    "            \"\",\n",
    "            \"Robot Features:\",\n",
    "            \"- Neural network controller\",\n",
    "            \"- 5 distance sensors\",\n",
    "            \"- 2 motor outputs\",\n",
    "            \"\",\n",
    "            \"Evolution Process:\",\n",
    "            \"- Selection of fittest robots\",\n",
    "            \"- Mutation of neural weights\",\n",
    "            \"- Inheritance of behaviors\",\n",
    "            \"\",\n",
    "            f\"Generation: {self.generation}\",\n",
    "            f\"Population: {len(self.population)}\",\n",
    "            f\"Best Fitness: {max(r.fitness for r in self.population):.2f}\"\n",
    "        ]\n",
    "        self.ax_info.text(0, 1, '\\n'.join(info), va='top')\n",
    "\n",
    "def create_evolution_animation(num_frames=500):\n",
    "    print(\"Starting Evolutionary Robotics Simulation...\")\n",
    "    \n",
    "    sim = EvolutionarySimulation(population_size=20)\n",
    "    \n",
    "    anim = FuncAnimation(sim.fig, sim.update, frames=num_frames,\n",
    "                        interval=50, blit=False)\n",
    "    \n",
    "    writer = PillowWriter(fps=30)\n",
    "    anim.save('evolutionary_robotics.gif', writer=writer)\n",
    "    \n",
    "    print(\"\\nSimulation completed!\")\n",
    "    print(\"Check 'evolutionary_robotics.gif' for the animation\")\n",
    "\n",
    "# Run the simulation\n",
    "create_evolution_animation(num_frames=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
